# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

## Project Overview

MindSpider is an AI-powered sentiment crawler for Chinese social media platforms. It operates as a two-stage pipeline:

1. **BroadTopicExtraction (ç¬¬ä¸€é˜¶æ®µ)**: å¹¿æ³›è¯é¢˜æå–
   - **é˜¶æ®µ 1.1 - æ•°æ®é‡‡é›†**: ä»å¤šä¸ªä¿¡æºçˆ¬å–çƒ­æ¦œã€æ–°é—»ã€èµ„è®¯ï¼Œå­˜å…¥ MongoDB
   - **é˜¶æ®µ 1.2 - AI çƒ­ç‚¹åˆ†æ**: ä» MongoDB ä¸­ç”¨ AI åˆ†ææå–çƒ­ç‚¹è¯é¢˜
2. **DeepSentimentCrawling (ç¬¬äºŒé˜¶æ®µ)**: åŸºäºçƒ­ç‚¹è¯é¢˜æ·±å…¥çˆ¬å– 7 ä¸ªç¤¾äº¤å¹³å°çš„è¯¦ç»†å†…å®¹

### å¼€å‘è¿›åº¦

| é˜¶æ®µ | çŠ¶æ€ | è¯´æ˜ |
|------|------|------|
| 1.1 æ•°æ®é‡‡é›† | âœ… å·²å®Œæˆ | 8 ä¸ªèšåˆå™¨ï¼Œ15 ä¸ªçˆ¬è™«ï¼Œ30+ æ•°æ®æº |
| 1.2 AI çƒ­ç‚¹åˆ†æ | ğŸš§ å¾…å¼€å‘ | ä» MongoDB æå–çƒ­ç‚¹ |
| 2.0 æ·±åº¦çˆ¬å– | ğŸ“‹ è®¡åˆ’ä¸­ | 7 å¹³å°è¯¦ç»†å†…å®¹çˆ¬å– |

## Python ç¯å¢ƒ

æœ¬é¡¹ç›®ç»Ÿä¸€ä½¿ç”¨ **uv** ä½œä¸º Python åŒ…ç®¡ç†å’Œè¿è¡Œç¯å¢ƒã€‚

```bash
# å®‰è£… uv (å¦‚æœå°šæœªå®‰è£…)
# Windows: powershell -c "irm https://astral.sh/uv/install.ps1 | iex"
# Linux/macOS: curl -LsSf https://astral.sh/uv/install.sh | sh

# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒå¹¶å®‰è£…ä¾èµ–
uv venv
uv pip install -e ".[dev]"
uv run playwright install chromium
```

## Commands

### Installation
```bash
uv pip install -e .
uv run playwright install chromium
uv pip install -e ".[dev]"  # for development
```

### Running the Project
```bash
# Full workflow (topic extraction + crawling)
uv run python main.py --complete

# Individual stages
uv run python main.py --broad-topic --keywords 100
uv run python main.py --deep-sentiment --platforms xhs dy bili --max-keywords 50 --max-notes 50

# Setup and status
uv run python main.py --setup
uv run python main.py --status
uv run python main.py --init-db

# Test mode (reduced data)
uv run python main.py --complete --test
```

### Module-specific Commands
```bash
# BroadTopicExtraction
cd BroadTopicExtraction && uv run python main.py --keywords 100 --list-sources

# DeepSentimentCrawling
cd DeepSentimentCrawling && uv run python main.py --guide
cd DeepSentimentCrawling && uv run python main.py --list-topics --days 7
cd DeepSentimentCrawling && uv run python main.py --platform xhs --max-notes 50
```

### Code Quality
```bash
uv run black .              # format
uv run ruff check .         # lint
uv run mypy .               # type check
uv run pytest tests/ -v     # test
uv run pre-commit run --all-files
```

## Architecture

```
News Sources â†’ BroadTopicExtraction â†’ daily_topics table â†’ DeepSentimentCrawling â†’ Platform-specific tables
```

### Key Entry Points
- `main.py` - Root orchestrator (`MindSpider` class) - coordinates both stages
- `BroadTopicExtraction/main.py` - Topic extraction CLI (`BroadTopicExtraction` class)
- `DeepSentimentCrawling/main.py` - Crawling CLI (`DeepSentimentCrawling` class)

### Core Components
- `BroadTopicExtraction/topic_extractor.py` - AI-powered keyword extraction using DeepSeek API
- `BroadTopicExtraction/get_today_news.py` - News collection from multiple Chinese sources
- `DeepSentimentCrawling/keyword_manager.py` - Retrieves topics and manages keyword distribution
- `DeepSentimentCrawling/platform_crawler.py` - Multi-platform crawler orchestrator
- `DeepSentimentCrawling/MediaCrawler/` - Platform-specific crawlers using Playwright

### Database
- Schema: `schema/mindspider_tables.sql`
- ORM models: `schema/models_sa.py`
- Core tables: `daily_news`, `daily_topics`, `topic_news_relation`, `crawling_tasks`
- Platform tables: `xhs_note`, `douyin_aweme`, `kuaishou_video`, `bilibili_video`, `weibo_note`, `tieba_note`, `zhihu_content`

### Configuration
- `.env` - Environment variables (database credentials, API keys)
- `config.py` - Generated from `config.py.example`, uses Pydantic Settings
- Supports MySQL and PostgreSQL
- AI API: DeepSeek recommended (`MINDSPIDER_API_KEY`, `MINDSPIDER_BASE_URL`)

## Platform Codes
- `xhs` - Xiaohongshu (å°çº¢ä¹¦)
- `dy` - Douyin (æŠ–éŸ³)
- `ks` - Kuaishou (å¿«æ‰‹)
- `bili` - Bilibili (å“”å“©å“”å“©)
- `wb` - Weibo (å¾®åš)
- `tieba` - Tieba (è´´å§)
- `zhihu` - Zhihu (çŸ¥ä¹)

## Notes
- `BroadTopicExtraction.run_daily_extraction()` is async - uses `asyncio.run()` for execution
- Most platforms require login (QR code, phone, or cookie-based)
- Crawlers include delays to avoid platform rate limiting
- Commercial use requires written permission from original MediaCrawler author

## é¡¹ç›®ä¼˜ç¼ºç‚¹åˆ†æ

### ä¼˜ç‚¹

**1. æ™ºèƒ½åŒ–çš„ä¸¤é˜¶æ®µæ¶æ„**
- å…ˆé€šè¿‡ AI æå–çƒ­ç‚¹è¯é¢˜ï¼Œå†é’ˆå¯¹æ€§çˆ¬å–ï¼Œæ¯”ç›²ç›®å…¨é‡çˆ¬å–æ›´é«˜æ•ˆ
- è¯é¢˜ä¸å†…å®¹é€šè¿‡ `topic_id` å…³è”ï¼Œä¾¿äºåç»­èˆ†æƒ…åˆ†æ

**2. å¤šå¹³å°ç»Ÿä¸€ç®¡ç†**
- 7 ä¸ªä¸»æµä¸­æ–‡ç¤¾äº¤å¹³å°ç»Ÿä¸€æ¥å£
- ç»Ÿä¸€çš„æ•°æ®æ¨¡å‹å’Œå­˜å‚¨ç»“æ„

**3. é…ç½®çµæ´»**
- æ”¯æŒ MySQL/PostgreSQL åŒæ•°æ®åº“
- AI API å¯åˆ‡æ¢ï¼ˆDeepSeek æˆæœ¬æ›´ä½ï¼‰
- Pydantic Settings ç®¡ç†é…ç½®ï¼Œç±»å‹å®‰å…¨

**4. å¼€å‘è§„èŒƒå®Œå–„**
- å®Œæ•´çš„ä»£ç è´¨é‡å·¥å…·é“¾ï¼ˆblackã€ruffã€mypyã€pytestï¼‰
- å¼‚æ­¥æ”¯æŒï¼Œæ•°æ®åº“è¿æ¥æ± 

### ç¼ºç‚¹

**1. å•æœºæ¶æ„ï¼Œæ— æ³•æ°´å¹³æ‰©å±•**
- æ²¡æœ‰åˆ†å¸ƒå¼ä»»åŠ¡é˜Ÿåˆ—ï¼ˆå¦‚ Celery + Redisï¼‰
- æ²¡æœ‰å¤šèŠ‚ç‚¹åè°ƒæœºåˆ¶
- å¤§è§„æ¨¡çˆ¬å–æ—¶ä¼šæˆä¸ºç“¶é¢ˆ

**2. åçˆ¬èƒ½åŠ›è¾ƒå¼±**
- ä»…é ç®€å•å»¶è¿Ÿå’Œä»£ç†
- ç¼ºä¹æŒ‡çº¹ä¼ªè£…ã€éªŒè¯ç è¯†åˆ«ç­‰é«˜çº§åæ£€æµ‹
- ä¾èµ– Playwright æµè§ˆå™¨è‡ªåŠ¨åŒ–ï¼Œèµ„æºæ¶ˆè€—å¤§

**3. è¿ç»´èƒ½åŠ›ä¸è¶³**
- ç¼ºä¹ç›‘æ§å‘Šè­¦ç³»ç»Ÿ
- æ²¡æœ‰ä»»åŠ¡é‡è¯•ã€æ–­ç‚¹ç»­çˆ¬æœºåˆ¶
- ç™»å½•æ€ç®¡ç†éœ€è¦äººå·¥ä»‹å…¥ï¼ˆæ‰«ç ï¼‰

**4. æ•°æ®å¤„ç†èƒ½åŠ›æœ‰é™**
- ä¸»è¦æ˜¯é‡‡é›†å­˜å‚¨ï¼Œç¼ºä¹å®æ—¶åˆ†æç®¡é“
- æ²¡æœ‰æƒ…æ„Ÿåˆ†ææ¨¡å—ï¼ˆåå­—å« Sentiment ä½†å®é™…åªæ˜¯çˆ¬å–ï¼‰

### é€‚ç”¨åœºæ™¯

æœ¬é¡¹ç›®æ›´é€‚åˆ**å°è§„æ¨¡ã€ç ”ç©¶æ€§è´¨**çš„èˆ†æƒ…ç›‘æµ‹åœºæ™¯ã€‚å¦‚æœè¦åšç”Ÿäº§çº§çš„é›†ç¾¤çˆ¬è™«ç³»ç»Ÿï¼Œéœ€è¦è¡¥å……åˆ†å¸ƒå¼è°ƒåº¦ã€åçˆ¬å¯¹æŠ—ã€ç›‘æ§å‘Šè­¦ç­‰èƒ½åŠ›ã€‚
