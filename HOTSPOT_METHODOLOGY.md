# 舆情热点分析：设计哲学与方法论

## 一、如何发现热点？

业界的共识是**多信号交叉验证**，不依赖单一指标。

### 1. 绝对热度信号
最直观的——某条新闻在某个平台上的 hot_value 很高。但这个信号噪声大，抖音上一条娱乐视频轻松过千万热度，不代表它是重要新闻。我们的数据也验证了这一点：抖音 top 30 里大量是「永远会被老一辈的爱情感动」这类内容。

### 2. 跨平台共振信号
这是业界公认最强的热点指标。一个事件如果同时出现在微博、百度、头条、抖音多个平台的热搜上，几乎可以确定是真正的热点。我们的数据里「中国女特警上演神级补枪」同时出现在 sina、toutiao、baidu 三个平台，这种跨平台共振比单平台高热度可靠得多。

### 3. 权威媒体背书信号
央媒（新华网、人民日报、央视）报道的话题，即使社交媒体热度不高，也可能是重大事件。反过来，如果一个话题既有社交媒体热度又有央媒报道，重要性可以确认。

### 4. 话题聚类信号
同一事件在不同平台上标题不同（「中戏表演系主任王鑫主动投案」vs「中戏表演系原主任陈刚主动投案」），需要语义聚类才能识别。这是纯算法做不好、需要 LLM 的地方。

---

## 二、如何尽快尽早发现热点？

这是最有价值的能力。学术界有一个经典模型——**Kleinberg 突发检测算法**（2002），核心思想是：不看绝对值，看**变化率**。

### 1. 突发检测（Burst Detection）
Kleinberg 的方法把时间序列建模为一个状态机，正常状态下事件以基准速率发生，突发状态下速率显著升高。关键不是「现在热度多高」，而是「热度增长速度有多快」。

映射到我们的系统：一条新闻 30 分钟前 hot_value 是 10 万，现在是 100 万，增长率 900%——这比一条稳定在 500 万的老新闻更值得关注。我们的数据里「广东湛江发现疑似儒艮尸体」增长率 8359%，就是典型的突发信号。

### 2. 首次上榜检测（New Entry Detection）
一条新闻第一次出现在任何一个热搜榜上的那一刻，就是最早的信号。如果它一上榜就在高位（比如直接进入 Top 10），说明爆发力极强。

### 3. 跨平台扩散速度
一个话题从单平台扩散到多平台的速度，是预判其是否会成为全国性热点的关键指标。如果一条新闻 10:00 只在头条上，10:30 出现在百度，11:00 出现在微博——这个扩散速度本身就是一个强信号。

### 4. Twitter/X 的做法
根据公开资料，Twitter 的 trending 算法核心不是看绝对量，而是看**相对于基线的异常程度**。它用 EWMA（指数加权移动平均）建立每个话题的基线频率，然后用统计检验（Poisson surprise）检测偏离基线的程度。这意味着一个平时没人讨论的话题突然有 1000 人讨论，比一个平时就有 10 万人讨论的话题多了 1 万人讨论更「trending」。

---

## 三、如何找到热点的传播规律？

学术研究（特别是 Springer 上那篇基于机器学习的舆情演化分析）把舆情事件的生命周期分为四个阶段：

```
热度
 ↑
 │          ╭──╮
 │         ╱    ╲
 │        ╱      ╲
 │       ╱        ╲──────
 │    ╱╱            ╲
 │  ╱                 ╲───────
 │╱
 └──────────────────────────→ 时间
   潜伏期  爆发期  蔓延期  消退期
```

### 1. 潜伏期（Latent）
事件已经发生，但只在小范围传播。可能只出现在一个地方媒体或一个垂直社区。我们的系统在这个阶段能做的是：监测 `first_seen_at` 刚出现的新条目，特别是那些一出现就带有较高初始热度的。

### 2. 爆发期（Burst）
热度急剧上升，跨平台扩散。hot_value_history 呈现陡峭上升曲线，多个平台几乎同时出现。这是我们的信号检测层最容易捕捉的阶段。

### 3. 蔓延期（Spread）
热度维持在高位，可能出现二次话题（衍生讨论、官方回应、反转等）。在我们的数据里表现为：长时间停留在榜单上（history 深度大），但 hot_value 波动不大。

### 4. 消退期（Decay）
热度逐渐下降，从各平台热搜上消失。`last_seen_at` 不再更新，position 逐渐下滑。

### 传播规律的关键发现
来自 Frontiers 上的 SIR 模型研究：
- 关键节点（大V、官方媒体）的介入会显著加速传播
- 普通节点的传播会自然衰减
- 政策回应或官方声明通常会造成热度的二次峰值
- 大多数热点的活跃期在 1-3 天，少数重大事件可持续数周

---

## 四、如何研判热点的传播趋势？

这是最难的部分，本质上是**预测**。

### 1. 曲线拟合法
用 hot_value_history 的时间序列数据，拟合到已知的传播模型（如 SIR 传染病模型、Bass 扩散模型）。根据当前所处的阶段，预测后续走势。如果一个话题的热度曲线符合爆发期的特征（指数增长），可以预判它还会继续上升。

### 2. 类比法
找到历史上传播模式相似的事件，用它们的后续走势来预测当前事件。比如「官员落马」类新闻通常有固定的传播模式：爆发→官方通报→二次讨论→消退，整个周期约 2-3 天。

### 3. 多维度综合研判
- 事件性质：突发事故 > 政策发布 > 娱乐八卦（持续时间不同）
- 官方态度：是否有官方回应？回应是否充分？
- 情感极性：负面情绪的话题传播更快、持续更久
- 是否有新信息注入：反转、后续进展会延长生命周期

### 4. LLM 的角色
传统算法擅长检测数值信号（热度变化、跨平台计数），但不擅长理解事件的**语义本质**。LLM 可以判断：
- 这个事件的性质是什么（政治敏感？民生问题？娱乐？）
- 历史上类似事件的传播模式是怎样的
- 当前是否存在可能引发二次爆发的因素
- 这个话题对特定行业/群体的影响程度

---

## 五、数据源的角色分化：不同信源的本质差异

这是一个容易被忽视但极其关键的设计问题。我们从多个平台采集数据，但这些数据的**性质完全不同**，不能用同一套逻辑处理。

### 1. 信息生态的四层结构

中国互联网的信息传播存在一个清晰的层级结构：

```
权威层（央媒）
  │  发布 → 定调 → 引导
  ▼
全国热搜层（社交平台全国热榜）
  │  放大 → 发酵 → 共振
  ▼
地方热搜层（社交平台地方热榜）
  │  地方事件 → 区域传播 → 冒泡
  ▼
垂直层（行业社区）
  │  深挖 → 解读 → 扩散
```

这四层之间的互动关系，本身就是舆情分析的核心对象：

- **自上而下**：央媒发布重大政策 → 全国热搜热议 → 地方/垂直社区解读。这种模式下，media 数据是**先行指标**。
- **自下而上（地方冒泡）**：地方事件在某省热搜发酵 → 扩散到邻省 → 冲上全国热搜 → 央媒跟进。这种模式下，hot_local 是**最早信号**。
- **自下而上（行业破圈）**：垂直社区爆出行业事件 → 社交媒体扩散 → 央媒跟进报道。这种模式下，hot_vertical 是**先行指标**。
- **平行共振**：突发事件同时在多个社交平台爆发，央媒迅速跟进。这种模式下，cross_platform 共振是**核心信号**。

### 1.1 层级跃迁：统一的早期预警模型

上述四层结构揭示了一个统一的规律：**热点的本质是话题在层级之间的跃迁**。无论是地方冒泡到全国、行业破圈到大众、还是社交媒体倒逼央媒关注，底层逻辑都是同一个——话题从低影响力层级向高影响力层级的跳跃。

```
低层级 → 高层级 = 影响力升级信号

地方榜 → 全国榜       = 地理破圈（geographic_break）
垂直榜 → 全国榜       = 行业破圈（vertical_break）
社交媒体 → 央媒报道    = 倒逼权威关注（reverse_authority）
央媒报道 → 社交媒体    = 权威引爆（authority_ignite）
单省地方榜 → 多省地方榜 = 地理扩散（geographic_spread）
```

这五种跃迁可以用**同一个检测逻辑**实现：标题匹配 + 时间差计算。先出现在 A 层级，后出现在 B 层级，时间差越短说明跃迁越猛烈，话题的爆发潜力越大。

这个模型的价值在于：它把「早期预警」从一个模糊的概念变成了一个可量化的指标——**跃迁速度**。一个话题从地方榜冒泡到全国榜用了 30 分钟，和用了 6 小时，代表着完全不同的爆发力。

### 2. 社交媒体热榜的特殊性

社交媒体热榜（微博、百度、头条、抖音等）是我们的主信号源，但需要理解它们的局限：

- **平台算法偏见**：每个平台的热榜算法不同。抖音偏娱乐，百度偏时事，微博偏社会话题。单一平台的热度排名反映的是该平台用户群体的偏好，不是事件的客观重要性。
- **热度≠重要性**：一条明星八卦在微博上的热度可能远超一项重大政策。但从舆情分析的角度，后者的重要性远高于前者。
- **跨平台共振消除偏见**：正因为每个平台有自己的偏见，当一个话题同时突破多个平台的算法筛选出现在各自的热榜上时，说明它的传播力已经超越了单一平台的用户圈层——这才是真正的全民热点。

这就是为什么**跨平台共振**是最强信号：它本质上是用多个有偏见的观察者的交集来逼近客观事实。

### 3. 传统媒体的独特价值

传统媒体（新华社、央视、人民日报等）在我们的系统中不产生热度数据，但它们的价值不可替代：

- **权威定性**：央媒报道一个事件，等于给这个事件盖了「重要」的章。这不是热度能衡量的。
- **早期预警**：有些重大事件（政策变动、外交动态、重大案件）是央媒先发布，社交媒体后跟进。如果我们只看社交媒体热榜，会错过这个时间窗口。
- **二次催化**：一个已经在社交媒体上发酵的话题，如果央媒跟进报道（特别是批评性报道），往往会引发热度的二次爆发。央媒的介入本身就是一个传播加速器。

因此，media 数据的正确用法不是参与热度排名，而是作为**权威背书层**和**早期预警层**。

### 4. 垂直社区的破圈信号

垂直社区（科技：掘金、36氪、IT之家；财经：财联社、雪球）的热度基线与全国热搜完全不同。掘金热榜第一名的热度值可能只有微博热搜第 50 名的零头。

但垂直社区有一个独特价值：**破圈检测**。

当一个话题从垂直社区「溢出」到全国热搜时，意味着：
- 它已经超越了专业圈层的关注范围
- 它可能正在从「行业事件」演变为「社会事件」
- 它的传播潜力被低估了

典型案例：一个 AI 模型发布的消息可能先在掘金/36氪上热议，然后扩散到微博/百度热搜。这个「从垂直到全国」的跃迁过程，是判断话题影响力升级的关键信号。

### 5. 地方热搜的冒泡信号

地方热搜（按省市划分的社交媒体热榜）是整个系统中**潜在的最早信号源**。

很多重大全国性事件的生命起点在地方层面：一起安全事故、一个地方官员落马、一场极端天气——这些事件先出现在事发地的地方热搜上，然后才逐步扩散到全国视野。地方榜到全国榜之间的时间差，就是早期预警的窗口期。

地方热搜的检测分为两个层次：

**内部检测（最早信号）**：对地方榜本身做热度飙升检测（velocity）。一个话题在某省热搜上的热度急剧上升，说明事件正在本地剧烈发酵，即使尚未扩散到其他地区，这个上升速率本身就预示着高爆发潜力。这是整个系统中理论上最早的信号——比跨区域扩散更早，比冒泡到全国榜更早。需要注意的是，地方榜热度基数小、正常波动比例大，velocity 阈值应比全国榜更激进（更高的增长率要求或更高的绝对值下限），以过滤噪声。

**跨层检测（扩散信号）**：
- **冒泡检测**：一个地方榜话题的标题出现在全国热搜上，说明它已经完成了从地方到全国的跃迁。跃迁速度（时间差）越短，说明事件爆发力越强。
- **地理扩散检测**：一个话题从单省地方榜扩散到多省地方榜（≥2 个省），说明它正在突破地域限制，有成为全国热点的潜力。这个信号甚至比冒泡到全国榜更早。

三者构成一个时间递进的预警链：

```
本省 velocity 飙升 → 扩散到邻省 → 冲上全国热搜 → 央媒跟进
（最早预警）      （扩散预警）  （确认爆发）    （权威确认）
```

地方热搜的噪声很大（31 个省 × 50 条 = 1550 条，绝大多数永远不会成为全国热点），因此它的正确用法不是作为主信号源，而是作为**潜伏期探测器**——只关注那些出现跨区域扩散或向全国榜跃迁迹象的话题。

### 6. 聚合平台的去噪价值

聚合平台（今日热榜、NewsNow、热榜等）本质上是对原始平台数据的二次采集。它们与我们直接采集的数据存在大量重叠。

它们的价值不在于提供新信息，而在于：
- **数据冗余**：当某个平台的官方 API 或直接爬取失败时，聚合平台可以兜底
- **交叉验证**：同一条新闻如果在官方 API、今日热榜、NewsNow 三个渠道都出现且数据一致，说明数据可靠
- **覆盖补充**：聚合平台可能覆盖了我们没有直接爬取的小众平台

因此，聚合平台数据应该在去重后作为补充，而不是作为独立信号源。否则会导致同一条新闻被重复计数，人为放大其重要性。

### 7. 核心设计原则：角色分工，交叉验证

综合以上分析，数据源的处理哲学可以归纳为：

> **不同数据源回答不同的问题。社交媒体全国热榜回答「大众在关注什么」，地方热榜回答「哪里正在发生什么」，传统媒体回答「什么是重要的」，垂直社区回答「专业领域在发生什么」。真正的洞察来自这四个答案的交叉点和层级跃迁。**

具体而言：
- **社交媒体全国热榜**：主信号源，提供热度时间序列，适用突发检测、跨平台共振等算法
- **社交媒体地方热榜**：潜伏期探测器，专注冒泡检测和地理扩散检测，捕捉最早信号
- **传统媒体**：权威背书层，不参与热度计算，用于确认重要性和早期预警
- **垂直社区**：领域信号源，独立阈值体系，关注破圈信号
- **聚合平台**：数据冗余层，去重后补充，不产生独立信号

这种分层处理的思路，避免了「把所有数据扔进同一个算法」的粗暴做法，也避免了「每个数据源单独分析互不关联」的孤岛问题。

---

## 六、早期预警库：候选话题的生命周期追踪

### 问题

信号检测层（Tier 1）每 30 分钟产生一批信号（velocity、new_entry、cross_platform 等），这些信号是**点状事件**——记录的是「某个时刻检测到某个异动」。但我们真正需要跟踪的是**实体**——「某个话题从出现到现在的完整演化轨迹」。

目前的架构中，signals collection 和 daily_topics 之间缺少一个中间层。signals 是碎片化的，daily_topics 是最终结果。没有一个地方把同一个话题的多个信号串联起来，形成连贯的画面。

### 设计：candidates collection

早期预警库本质上是一个**候选话题的状态机**，用硬编码实现，零 LLM 成本：

```
信号检测（每30分钟）
    │
    ├── 发现新信号 → 候选话题不存在 → 创建新候选，入库（status: emerging）
    ├── 发现新信号 → 候选话题已存在 → 更新候选，追加信号，评估升级
    └── 未发现新信号 → 候选话题已存在 → 检查衰退条件
```

候选话题的状态流转：

```
                    ┌── 快速通道（极高热度/排位/权威媒体）──┐
                    │                                      ▼
emerging（萌芽）→ rising（上升）→ confirmed（确认）→ exploded（爆发）
                                       │                  │
                                       ▼                  ▼
                                  tracking（追踪）←────────┘
                                       │         (爆发减弱后降级)
                                  ┌────┼────┐
                                  ▼    ▼    ▼
                             再次爬取 closed 聚类合并
                            (可重回   (已关闭)
                            exploded)

任意早期状态 → faded（衰退消失）
```

状态转换规则（硬编码）：
- **emerging → rising**：累积 ≥ 2 个不同类型的信号，或跨平台数 ≥ 2
- **rising → confirmed**：跨平台数 ≥ 3，或被 LLM 晨报/晚报确认，或快速通道
- **confirmed → exploded**：确认后持续爆发性增长，或快速通道极端情况（position ≤ 1 + 跨平台 ≥ 4）
- **confirmed/exploded → tracking**：深层爬取完成且爆发减弱
- **tracking → 再次爬取**：热度再次飙升（velocity 信号），极端情况可重回 exploded
- **tracking → closed**：长时间无新活动
- **任意早期状态 → faded**：连续 N 个检测周期无新信号且热度下降

exploded 与 confirmed 的区别：
- **爬取频率**：confirmed 触发一次全平台爬取；exploded 最高频持续爬取（如每小时增量）
- **LLM 分析**：confirmed 等晨报/晚报；exploded 立即触发即时分析
- **客户推送**：confirmed 常规推送；exploded 最高优先级紧急推送

每个候选话题记录：
- 首次检测时间、首次出现平台
- 关联的所有信号 ID 列表
- 当前跨平台数、最高热度、当前状态
- 热度时间序列快照（用于后续指纹分析）

### 价值

1. **为 LLM 提供结构化输入**：Tier 2 分析时，不再需要从海量原始数据中筛选，直接读取 candidates 中 rising 状态的话题即可
2. **追踪预测准确率**：事后可以统计 emerging 话题中有多少最终变成了 confirmed，用于调优阈值
3. **为指纹库积累数据**：每个走完生命周期的候选话题，都是一条传播指纹记录

---

## 七、语义匹配：硬编码粗筛 + LLM 精筛

### 问题

同一事件在不同平台上的标题往往不同：
- 「中戏表演系主任王鑫主动投案」
- 「中戏表演系原主任陈刚主动投案」
- 「知名戏剧学院领导落马」

纯字符串匹配（去标点后精确匹配或包含关系）只能处理前两种情况，第三种完全不同的表述就无能为力了。但如果每 30 分钟都调用 LLM 做语义匹配，又违背了 Tier 1 零成本的原则。

### 设计：两级匹配

**Tier 1 硬编码匹配（每 30 分钟）**

三种递进的匹配策略，命中任一即视为同一话题：

1. **去标点精确匹配**：去除所有标点符号和空格后，字符串完全相同
2. **包含关系匹配**：一个标题是另一个标题的子串（处理「标题+平台后缀」的情况）
3. **核心实体词匹配**：提取标题中的关键实体（人名、地名、机构名、数字），计算实体重叠率。可以用简单的规则实现：
   - 中文人名：2-4 个汉字，前面常有「某某」「原」「前」等前缀
   - 地名/机构名：维护一个常见地名和机构名词典
   - 数字+单位：正则提取（如「8359%」「100万」）
   - 实体重叠率 ≥ 60% 视为同一话题

这三种策略能覆盖约 70-80% 的同一事件不同标题情况。

**Tier 2 LLM 语义聚类（每天 2 次）**

晨报/晚报分析时，把早期预警库中所有 emerging 和 rising 状态的候选话题交给 LLM，做深度语义匹配和合并。这一步解决硬编码搞不定的那 20-30%——完全不同表述但指向同一事件的情况。

LLM 还可以做一件硬编码做不到的事：**判断两个看似相关但实际是不同事件的话题**。比如「北京暴雨」和「广州暴雨」共享关键词「暴雨」，硬编码可能误合并，但 LLM 能理解这是两个独立事件。

### 匹配结果的应用

匹配成功后，在 candidates collection 中合并为同一个候选话题：
- 保留所有原始标题（source_titles 列表）
- 选择最具代表性的标题作为 canonical_title（Tier 1 用最高热度的标题，Tier 2 由 LLM 生成简洁话题名）
- 累加跨平台计数

---

## 八、热点传播指纹库：从经验猜测到数据驱动

### 问题

当 LLM 被要求预测一个热点的后续走势时，它只能依赖训练数据中的通用知识。但每个舆情系统监测的领域、平台、用户群体都不同，通用知识的适用性有限。

如果我们能告诉 LLM：「过去 30 天，本系统监测到的 12 起『官员落马』类事件，平均生命周期 2.3 天，73% 出现了二次峰值，二次峰值通常由官方通报触发」——这比让 LLM 凭空猜测靠谱得多。

### 设计：分两阶段实施

**第一阶段（立即实施）：数据采集**

在早期预警库的候选话题走完生命周期（status 变为 confirmed 或 faded）后，自动提取传播指纹并存入 fingerprints collection：

```
{
  "topic_key": "中戏主任投案",
  "category": "社会",
  "outcome": "confirmed",          // 最终是否成为热点
  "fingerprint": {
    "first_seen_at": 1707700000,
    "first_platform": "weibo",
    "peak_hot_value": 5000000,
    "peak_platform_count": 5,
    "total_duration_hours": 48,
    "time_to_cross_platform": 1.5,  // 从单平台到跨平台的小时数
    "time_to_authority": 4.0,       // 从首次出现到央媒报道的小时数
    "has_second_peak": true,
    "second_peak_trigger": "官方通报",
    "timeline": [
      {"ts": 1707700000, "event": "new_entry", "platform": "weibo"},
      {"ts": 1707701800, "event": "velocity", "growth_rate": 3.5},
      {"ts": 1707703600, "event": "cross_platform", "platforms": ["weibo", "baidu", "toutiao"]},
      {"ts": 1707710800, "event": "authority_boost", "media": ["xinhua"]},
      {"ts": 1707780000, "event": "decay_start"}
    ]
  }
}
```

这个阶段不需要 LLM 参与，纯硬编码从 candidates 的历史数据中提取。从系统运行第一天就开始积累。

**第二阶段（数据积累后）：构建参考模板，接入 LLM**

当 fingerprints collection 积累了足够多的记录（建议至少 100 条已完成生命周期的话题）后：

1. 按 category 分组，计算统计指标（平均生命周期、跨平台速度、二次峰值概率等）
2. 提取典型传播曲线模板
3. LLM 分析时，在 prompt 中附上同类事件的历史统计：

```
## 历史参考：近30天「官员落马」类事件传播模式（共12起）
- 平均生命周期: 2.3 天
- 典型路径: 单平台爆发 → 跨平台共振(平均2h) → 央媒跟进(平均4h) → 二次峰值 → 消退
- 二次峰值触发率: 73%（通常由官方通报引发）
- 最长持续: 5.2 天（涉及省部级以上）
- 最短持续: 0.8 天（地方处级，未引发广泛关注）
```

### 指纹库的长期价值

- **趋势预测**：当前话题的传播曲线与哪个历史模板最匹配？据此预测后续走势
- **阈值自适应**：根据历史数据动态调整信号检测的阈值，而不是靠人工拍脑袋
- **异常检测**：如果一个话题的传播模式显著偏离同类历史模板，本身就是一个值得关注的信号
- **系统评估**：统计早期预警的准确率、漏报率，持续优化检测算法

---

## 九、个性化：从通用热点到客户相关性

### 问题

全网热点检测是通用能力——「今天中国互联网上什么最热」对所有人都一样。但真实客户对「热点」的定义是个性化的：

- **品牌客户**（如茅台集团）：关心品牌相关事件（i茅台运营、假茅台投诉）、竞品动态、行业政策
- **地方媒体**（如重庆南岸区融媒体中心）：关心本区新闻、本市新闻，全国热点只是背景
- **行业用户**（如某科技公司）：关心行业动态、技术趋势，社会娱乐热点与其无关

这意味着同一个热点，对不同客户的价值完全不同。「微博热搜第一名」对茅台可能毫无意义，而一条没上任何热搜的「贵州某地查获假茅台」对茅台却至关重要。

### 核心原则：通用检测做一次，个性化过滤做 N 次

个性化不应该侵入通用热点检测系统。在能力化架构中，**客户过滤**是六个核心能力之一，与其他能力平等并行，通过共享数据层获取热点数据，独立计算客户相关性：

```
┌──────┐┌──────┐┌──────┐┌──────┐┌──────────────────────┐
│ 表层 ││ 深层 ││ 信号 ││ 话题 ││ 客户过滤              │
│ 采集 ││ 采集 ││ 检测 ││ 分析 ││ ┌──────┐┌──────┐     │
│      ││      ││      ││      ││ │品牌  ││地方  │ ... │
│      ││      ││      ││      ││ │客户  ││媒体  │     │
└──┬───┘└──┬───┘└──┬───┘└──┬───┘│ └──┬───┘└──┬───┘     │
   └───────┴───────┴───────┘    └────┴───────┴─────────┘
                 │                        │
                 ▼                        ▼
        ┌────────────────┐      ┌────────────────┐
        │   共享数据层     │      │  个性化输出      │
        │ MongoDB + MySQL │ ───→ │  客户报告/推送   │
        └────────────────┘      └────────────────┘
```

客户过滤能力从共享数据层读取通用热点结果，结合客户兴趣画像计算相关性，独立输出个性化报告。通用系统不感知客户存在，客户层独立演进。

### 客户兴趣画像

每个客户通过一个结构化的兴趣画像来定义「什么与我相关」：

```
client_profile = {
    "client_id": "moutai",
    "client_name": "茅台集团",
    "interest_type": "brand",           // brand / region / industry / general

    // 关键词体系（分层，权重不同）
    "core_keywords": ["茅台", "i茅台", "飞天茅台"],
    "extended_keywords": ["白酒", "酱香", "贵州茅台"],
    "competitor_keywords": ["五粮液", "泸州老窖", "洋河"],
    "negative_keywords": ["茅台村"],     // 排除噪声

    // 数据源权重（不同客户的主数据源不同）
    "source_weights": {
        "hot_national": 1.0,
        "hot_local": {"贵州": 2.0},      // 贵州地方榜加权
        "hot_vertical": {"finance": 1.5}, // 财经垂直加权
        "media": 1.0
    }
}
```

### 不同客户类型的主数据源差异

一个关键洞察：**不同类型的客户，主数据源完全不同**。通用热点检测对所有客户都有价值，但它不是每个客户的主要信息来源。

| 客户类型 | 主数据源 | 通用热点的角色 | 专属需求 |
|---------|---------|--------------|---------|
| 品牌客户 | 品牌关键词监测（全网） | 背景参考，关注品牌相关热点 | 品牌提及监测、竞品追踪、危机预警 |
| 地方媒体 | hot_local（本省/本市） | 背景参考，关注本地相关全国热点 | 本地事件全量监测、冒泡到全国的追踪 |
| 行业用户 | hot_vertical（本行业） | 背景参考，关注行业相关全国热点 | 行业动态全量监测、破圈事件追踪 |
| 通用用户 | hot_national（全国热搜） | 核心数据源 | 无特殊需求 |

这意味着：
- 对**地方媒体**客户，hot_local 从「潜伏期探测器」升级为**主数据源**——他们需要看到本地热搜的全部内容，而不仅仅是冒泡到全国的那几条
- 对**行业用户**，hot_vertical 从「领域信号源」升级为**主数据源**——他们需要看到行业榜单的全部内容
- 对**品牌客户**，通用热点系统甚至不是主要价值来源——他们最需要的是**关键词监测**，这本质上是一个不同的功能模块

### 个性化的两个层次

**层次一：过滤（从通用结果中筛选）**

最简单的个性化——从通用热点池中，按客户兴趣画像过滤出相关话题。这不需要额外的数据采集或分析，只是在输出端加一层筛选。

实现方式：
- 通用系统产出 daily_topics（每天 50 个热点）
- 客户过滤层对每个热点计算客户相关性评分
- 按评分排序，输出客户个性化的热点列表

**层次二：专属监测（通用系统覆盖不到的需求）**

有些客户需求超出了通用热点检测的范围：
- 品牌客户需要监测全网所有提到品牌名的内容，不管它是否上了热搜
- 地方媒体需要监测本地所有新闻，不管它是否有全国影响力
- 这些需求本质上不是「热点检测」，而是「关键词监测」或「区域监测」

这类需求应该作为独立的功能模块实现，与通用热点检测系统并行运行，共享底层数据采集基础设施，但有自己的检测逻辑和输出。

### 实施节奏

个性化是商业化阶段的需求，不是当前信号检测和话题分析能力建设的重点。但在设计基础设施时需要预留扩展点：

1. **现在**：专注通用热点检测，确保 daily_topics 输出质量
2. **下一步**：在 daily_topics 上增加 category、region、keywords 等标签字段，为后续过滤提供基础
3. **有客户时**：实现客户兴趣画像 + 相关性评分，按需增加专属监测模块

---

## 十、能力化架构：从线性流水线到事件驱动编排

### 设计动机

最初的系统设计是一条单向流水线：先发现热点，再深度爬取。但实际场景中这个假设不成立：

- 有些热点只有通过深度爬取才能发现（品牌危机在社交平台评论区酝酿，热榜上看不到）
- 早期预警的候选话题需要深度爬取来验证（光看热榜数据无法判断是否真的在发酵）
- 客户个性化监测需要独立触发深度爬取（不依赖通用热点检测）
- 深度爬取的结果应该反馈给热点检测（发现新信号、验证候选话题、丰富指纹库）

因此，系统中的每个模块都不应该是固定顺序的「步骤」，而应该是可以被多个触发源按需调用的「能力」。

### 六个核心能力

| 能力 | 职责 | 代码位置 |
|------|------|---------|
| 表层采集 | 爬热榜、媒体、聚合器，写入 MongoDB | `BroadTopicExtraction/` |
| 信号检测 | 硬编码算法发现异动，输出信号 | `BroadTopicExtraction/analyzer/` |
| 候选话题管理 | 话题生命周期状态机，触发决策 | `BroadTopicExtraction/analyzer/` |
| 深层采集 | 爬 7 个社交平台的详细内容（帖子、评论、讨论） | `DeepSentimentCrawling/` |
| 话题分析 | LLM 深度分析、聚类、研判 | `BroadTopicExtraction/analyzer/` |
| 客户过滤 | 个性化相关性评分、推送 | 新增 |

### 触发源

每个能力可以被多种触发源激活：

```
表层采集
  ├── 定时（每 30 分钟，常规巡检）
  ├── 客户（特定地方榜/垂直榜需要更高频采集）
  └── 事件（某候选话题需要追踪特定平台热榜变化）

信号检测
  ├── 定时（每 30 分钟，跟随表层采集）
  ├── 数据：新的表层数据到达 → 立即检测
  └── 反馈：深层采集发现异常讨论量 → 生成新信号

候选话题管理
  ├── 事件：收到新信号（信号检测产出）→ 纳入管理或状态升级
  ├── 事件：深层爬取完成（验证结果反馈）→ 加速或降级状态
  ├── 事件：话题分析结果（LLM 研判升降级）→ 更新状态
  ├── 事件：聚类分析结果（话题合并/更新）
  ├── 定时：周期性检查 tracking 状态话题（持续追踪）
  └── 定时：周期性清理衰退话题（faded/closed）

深层采集
  ├── 事件：候选话题 rising → 定向爬取验证是否真的在发酵
  ├── 事件：候选话题 confirmed → 全平台爬取充实报告
  ├── 事件：候选话题 exploded → 最高频持续爬取（全平台，每小时增量）
  ├── 客户：品牌关键词 → 定期搜索品牌提及
  ├── 定时：tracking 话题 → 持续追踪讨论变化
  └── 反馈：表层发现新话题 → 深层验证和充实

话题分析
  ├── 定时（晨报 08:00 / 晚报 20:00）
  ├── 事件：紧急信号（多个高优先级信号叠加）→ 即时分析
  ├── 事件：深层爬取完成 → 话题聚类分析
  └── 客户：客户请求专题分析

客户过滤
  ├── 数据：新的分析结果产出 → 计算客户相关性
  └── 配置：客户画像变更 → 重新计算
```

### 七条反馈环

能力之间不是单向流动，而是通过反馈环形成闭环：

**反馈环 1：信号检测 → 候选话题管理（新信号纳入管理）**

新信号产出后，候选话题管理将话题纳入管理或升级状态。这是最基本的驱动环——信号检测只负责"发现"，候选话题管理负责"决策"。

**反馈环 2：候选话题管理 → 深层采集（状态变化触发爬取）**

候选话题状态变化（rising/confirmed/exploded/再次爬取）触发不同规模的深层爬取。rising 触发验证性爬取，confirmed 触发全平台爬取，exploded 触发最高频持续爬取。

**反馈环 3：深层采集 → 信号检测（发现水面下的信号）**

深层采集在社交平台搜索某个话题，发现大量讨论但该话题从未出现在任何热搜榜上。这个「水面下」的讨论量本身就是一个信号，应该反馈给信号检测层，创建新的候选话题。

**反馈环 4：深层采集 → 候选话题管理（预警验证，提升准确率）**

早期预警库中的候选话题，仅靠热榜数据难以判断是否真的会爆发。深层采集可以去社交平台搜索相关关键词，用实际讨论量和情绪数据来验证候选话题的爆发潜力，加速或降级候选话题状态。

**反馈环 5：话题分析 → 候选话题管理（LLM 研判升降级）**

LLM 分析后判断某话题应升级或降级，更新候选话题状态。例如 LLM 判断某 rising 话题实际影响力有限，降级为 faded。

**反馈环 6：话题分析 → 深层采集（LLM 指导爬取方向）**

LLM 分析后判断某个话题可能有二次爆发风险（比如等待官方回应），或发现新角度需要补充数据，触发深层采集持续追踪。采集结果反馈给下一次分析，形成「分析→采集→再分析」的循环。

**反馈环 7：指纹库 → 信号检测（自适应阈值）**

传播指纹库积累了足够多的历史数据后，可以按话题类别统计传播规律，动态调整信号检测的阈值和时间窗口，让系统越跑越准。

### 架构总图

```
┌──────────────────────────────────────────────────────────────────┐
│                       调度与编排层                                  │
│              （事件驱动，管理触发、优先级、反馈）                     │
│                                                                    │
│  触发源: 定时 / 事件 / 客户 / 反馈 / 人工                          │
└──┬──────┬──────┬──────┬──────┬──────┬────────────────────────────┘
   │      │      │      │      │      │
   ▼      ▼      ▼      ▼      ▼      ▼
┌──────┐┌──────┐┌──────┐┌──────┐┌──────┐┌──────┐
│ 表层 ││ 信号 ││ 候选 ││ 深层 ││ 话题 ││ 客户 │  ← 六个能力
│ 采集 ││ 检测 ││ 管理 ││ 采集 ││ 分析 ││ 过滤 │    （平等并行）
└──┬───┘└──┬───┘└──┬───┘└──┬───┘└──┬───┘└──┬───┘
   │       │       │       │       │       │
   │  ┌────┴───────┴───────┴───────┴───┐   │
   │  │         反馈环网络               │   │
   │  │  信号→候选（新信号纳入管理）      │   │
   │  │  候选→深层（状态变化触发爬取）    │   │
   │  │  深层→信号（水面下信号）          │   │
   │  │  深层→候选（预警验证/状态更新）   │   │
   │  │  分析→候选（LLM 研判升降级）     │   │
   │  │  分析→深层（指导补充爬取）        │   │
   │  │  指纹→信号（自适应阈值）          │   │
   │  └────────────────────────────────┘   │
   │                                       │
   └───────────┬───────────────────────────┘
               ▼
      ┌────────────────┐
      │   共享数据层     │
      │ MongoDB + MySQL │
      │ 原始数据/候选话题 │
      │ 信号/指纹/报告   │
      └────────────────┘
```

### 场景一：常规热点发现全流程

一个普通的社会新闻从萌芽到确认的完整过程：

```
09:00  [表层采集·定时触发]
       常规爬取 → 百度热搜出现「某地化工厂爆炸」，排名第 38 位
       → 数据写入 MongoDB hot_national

09:00  [信号检测·数据触发]
       检测到 new_entry 信号：新上榜话题，初始排名中等
       → 创建候选话题，status: emerging
       → 写入 candidates collection

09:30  [表层采集·定时触发]
       常规爬取 → 该话题百度热搜升至第 15 位（position_jump）
       同时出现在头条热搜第 22 位（cross_platform: 2 个平台）

09:30  [信号检测·数据触发]
       检测到 position_jump + cross_platform 信号
       → 候选话题累积 3 个不同类型信号
       → status 升级: emerging → rising

09:30  [深层采集·事件触发：rising 状态触发验证]
       定向搜索「化工厂爆炸」→ 微博搜索、抖音搜索
       → 微博: 800+ 条讨论，情绪 90% 负面，多条现场视频
       → 抖音: 15 条现场视频，播放量快速增长

09:30  [信号检测·反馈触发：深层数据反馈]
       深层采集发现大量讨论 → 生成 discussion_surge 信号
       → 候选话题追加深层数据：讨论量、情绪分布
       → 综合评估：跨平台 2 个 + 深层讨论量大 + 强负面情绪

10:00  [表层采集·定时触发]
       该话题百度升至第 3 位，头条升至第 8 位
       新出现在微博热搜第 11 位（cross_platform: 3 个平台）
       新华社发布快讯（media collection 命中）

10:00  [信号检测·数据触发]
       velocity 信号 + cross_platform ≥ 3 + authority_boost（新华社）
       → status 升级: rising → confirmed
       → 写入传播指纹时间线

10:00  [深层采集·事件触发：confirmed 触发全平台爬取]
       全平台深度爬取：微博、抖音、小红书、B站、知乎……
       → 采集详细帖子、评论、转发链、情绪数据
       → 结果写入 MySQL 平台内容表

10:00  [话题分析·事件触发：紧急信号]
       多个高优先级信号叠加 → 触发即时 LLM 分析（不等晚报）
       → 结合表层数据（热度曲线、跨平台分布）
       → 结合深层数据（讨论量、情绪、关键意见）
       → 结合指纹库（历史上「安全事故」类事件模板）
       → 输出：确认为重大热点，预计持续 3-5 天，关注伤亡数字和官方回应

10:00  [客户过滤·数据触发]
       新热点产出 → 计算各客户相关性
       → 化工行业客户：相关性 100%，紧急推送
       → 事发地地方媒体客户：相关性 100%，紧急推送
       → 其他客户：作为全国热点常规推送

后续   [深层采集·定时触发：持续追踪]
       每小时追踪该话题讨论变化 → 数据反馈给话题分析
       → LLM 持续更新研判（是否有官方回应、是否有二次爆发）
       → 事件结束后 → 完整传播指纹入库
```

### 场景二：品牌客户个性化监测

茅台集团作为品牌客户，发现一起「假茅台」事件的过程：

```
09:00  [深层采集·客户触发：品牌关键词定时巡检]
       搜索「茅台」「i茅台」「飞天茅台」→ 小红书、微博、抖音
       → 小红书发现 30 篇「买到假茅台」帖子（过去 6 小时内发布）
       → 异常：过去同期平均只有 2-3 篇

09:00  [信号检测·反馈触发：深层数据反馈]
       深层采集发现异常讨论量 → 生成 discussion_surge 信号
       → 创建候选话题「假茅台投诉」，status: emerging
       → 标记来源：深层采集发现（非热榜发现）

09:30  [表层采集·定时触发]
       常规爬取 → 全国热搜上没有「假茅台」相关话题
       → 信号检测：候选话题无新的表层信号

09:30  [深层采集·事件触发：emerging 候选验证]
       扩大搜索范围 → 微博搜索「假茅台」
       → 发现 200+ 条讨论，多条带图投诉
       → 讨论量在增长中

09:30  [信号检测·反馈触发]
       深层数据显示多平台讨论量增长
       → 候选话题追加信号，跨平台讨论数 ≥ 2
       → status 升级: emerging → rising

10:00  [表层采集·定时触发]
       「假茅台」出现在微博热搜第 45 位
       → 信号检测：new_entry 信号 + 与候选话题匹配
       → 候选话题追加表层信号

10:00  [客户过滤·数据触发]
       rising 候选话题命中茅台客户 core_keywords
       → 相关性 100% → 预警推送给茅台客户
       → 此时话题还在微博热搜第 45 位，尚未引起广泛关注
       → 客户获得了宝贵的提前响应窗口

10:30  [表层采集·定时触发]
       「假茅台」微博热搜升至第 12 位
       → velocity 信号触发
       → 候选话题升级: rising → confirmed

10:30  [深层采集·事件触发：confirmed 全平台爬取]
       全平台深度爬取 → 采集详细投诉内容、传播链
       → 结果供话题分析使用

10:30  [话题分析·事件触发]
       LLM 分析 → 结合深层数据（投诉内容、情绪）
       → 结合指纹库（历史「品牌质量危机」模板）
       → 输出：预计持续 2-3 天，建议关注官方回应时间点
       → 推送给茅台客户：含详细分析报告

后续   持续追踪 → 事件结束 → 传播指纹入库 → 丰富「品牌危机」模板
```

### 两个场景的对比

| 维度 | 场景一（常规热点） | 场景二（品牌监测） |
|------|------------------|------------------|
| 首次发现来源 | 表层采集（热榜） | 深层采集（关键词搜索） |
| 发现时机 | 上榜即发现 | 上榜前发现（提前 1 小时） |
| 深层采集触发 | rising 状态触发验证 | 客户关键词定时触发 |
| 反馈环作用 | 深层数据充实候选话题 | 深层数据创建候选话题 |
| 客户价值 | 常规热点推送 | 提前预警 + 专属分析 |

场景二展示了反馈环的核心价值：**如果没有「深层采集 → 信号检测」这条反馈环，「假茅台」事件要等到上了微博热搜才会被发现，客户会损失至少 1 小时的响应时间。**

---

## 十一、总结：MindSpider 的设计哲学

MindSpider 是一个面向中文互联网的舆情热点监测系统。经过深入的方法论讨论，我们确立了以下设计哲学，它们贯穿系统的每一个设计决策。

### 核心理念：能力化事件驱动架构

系统由六个平等的核心能力组成，通过事件驱动编排协同工作：

```
┌──────────────────────────────────────────────────────────────────┐
│                       调度与编排层                                  │
│          触发源: 定时 / 事件 / 客户 / 反馈 / 人工                  │
└──┬──────┬──────┬──────┬──────┬──────┬────────────────────────────┘
   ▼      ▼      ▼      ▼      ▼      ▼
┌──────┐┌──────┐┌──────┐┌──────┐┌──────┐┌──────┐
│ 表层 ││ 信号 ││ 候选 ││ 深层 ││ 话题 ││ 客户 │
│ 采集 ││ 检测 ││ 管理 ││ 采集 ││ 分析 ││ 过滤 │
└──┬───┘└──┬───┘└──┬───┘└──┬───┘└──┬───┘└──┬───┘
   │  ┌────┴───────┴───────┴───────┴───┐   │
   │  │         反馈环网络               │   │
   │  └────────────────────────────────┘   │
   └───────────┬───────────────────────────┘
               ▼
      ┌────────────────┐
      │   共享数据层     │
      │ MongoDB + MySQL │
      └────────────────┘
```

| 能力 | 职责 | 代码位置 |
|------|------|---------|
| 表层采集 | 从 53+ 数据源采集热榜、媒体、聚合器数据 | `BroadTopicExtraction/` |
| 信号检测 | 硬编码算法实时发现异动，输出信号 | `BroadTopicExtraction/analyzer/` |
| 候选话题管理 | 话题生命周期状态机，触发决策 | `BroadTopicExtraction/analyzer/` |
| 深层采集 | 在 7 个社交平台爬取详细内容（帖子、评论） | `DeepSentimentCrawling/` |
| 话题分析 | LLM 深度分析、语义聚类、趋势研判 | `BroadTopicExtraction/analyzer/` |
| 客户过滤 | 个性化相关性评分，支持品牌/地方/行业客户 | 待实现 |

这些能力不是串行步骤，而是可以被多种触发源（定时、事件、客户需求、反馈数据）独立激活的服务。它们通过共享数据层交换信息，通过七条反馈环形成闭环：信号纳入候选管理、候选状态变化触发深层爬取、深层数据反哺信号检测、深层数据验证早期预警、LLM 研判升降级候选话题、LLM 分析指导爬取方向、指纹库驱动自适应阈值。

### 数据源哲学：不同信源回答不同问题

中文互联网的信息生态是分层的，我们的数据源对应四个层级：

| 层级 | 数据源 | 回答的问题 | 角色 |
|------|--------|-----------|------|
| 权威层 | 新华社、央视、人民日报 | 什么是重要的？ | 权威背书 + 早期预警 |
| 全国热搜层 | 微博、百度、头条、抖音热榜 | 大众在关注什么？ | 主信号源 |
| 地方热搜层 | 各省市地方热榜 | 哪里正在发生什么？ | 潜伏期探测器 |
| 垂直层 | 掘金、36氪、财联社、雪球 | 专业领域在发生什么？ | 领域信号源 |

真正的洞察来自这四个答案的交叉点和层级跃迁。一个话题从地方榜冒泡到全国榜、从垂直社区破圈到大众视野、从社交媒体倒逼央媒关注——这些跃迁本身就是最有价值的信号。

### 热点发现哲学：多信号交叉验证

不依赖单一指标，而是通过多维度信号的叠加来确认热点：

- **绝对热度**有噪声（娱乐内容轻松过千万），但**跨平台共振**几乎不会误判
- **变化率**比绝对值更重要（Kleinberg 突发检测的核心思想）
- **权威背书**可以确认重要性，**层级跃迁**可以预判爆发潜力
- 硬编码算法负责「看到数字」，LLM 负责「理解含义」

### 早期预警哲学：从信号到实体的追踪

信号是点状的（某个时刻检测到某个异动），但热点是有生命周期的实体。早期预警库（candidates collection）将碎片化的信号串联为候选话题的完整演化轨迹，通过状态机（emerging → rising → confirmed / faded）管理其生命周期。

候选话题的状态变化可以触发深层采集进行验证——这是反馈环的核心价值：不是等热点确认后才去爬取，而是在萌芽阶段就用深层数据来判断它是否值得关注。

### 语义匹配哲学：硬编码粗筛 + LLM 精筛

同一事件在不同平台上的标题往往不同。我们用两级匹配来解决：

- **Tier 1 硬编码**（每 30 分钟）：去标点精确匹配、包含关系、核心实体词重叠，覆盖 70-80%
- **Tier 2 LLM**（每天 2 次）：深度语义聚类，处理完全不同表述的情况

这种分级设计在实时性和成本之间取得平衡。

### 数据驱动哲学：传播指纹库

系统从第一天运行就开始积累每个话题的传播指纹——首次出现时间、跨平台速度、热度曲线、生命周期长度。随着数据积累，LLM 的趋势研判将从「基于通用知识猜测」进化为「基于本系统历史数据推理」，信号检测的阈值将从人工设定进化为数据驱动的自适应调整。

### 个性化哲学：通用检测做一次，个性化过滤做 N 次

不同客户对「热点」的定义不同：品牌客户关心品牌提及，地方媒体关心本地新闻，行业用户关心行业动态。但通用热点检测对所有客户都有价值。

客户过滤作为独立能力，从共享数据层读取通用结果，结合客户兴趣画像计算相关性。通用系统不感知客户存在，客户层独立演进。对于超出通用热点检测范围的需求（品牌关键词监测、区域全量监测），通过独立触发深层采集来实现。

### 边界声明

MindSpider 的职责边界是**舆情监测**——发现热点、追踪传播、分析趋势。舆情发展预判（预测事件走向）和舆情干预策略（建议应对措施）属于下游系统的职责，不在本项目范围内。本项目的输出（结构化热点数据、传播指纹、趋势分析报告）为下游系统提供数据基础。

---

## 参考资料

- [Structural Analysis of Online Public Opinion Evolution (Springer)](https://link.springer.com/article/10.1007/s44196-023-00277-8)
- [SIR Modeling of Public Opinion During COVID-19 (Frontiers)](https://www.frontiersin.org/journals/physics/articles/10.3389/fphy.2024.1462089/full)
- [Kleinberg Burst Detection Algorithm](https://nikkimarinsek.com/blog/kleinberg-burst-detection-algorithm)
- [Twitter Trending Algorithm (Quora)](https://www.quora.com/What-algorithm-is-used-to-find-trending-topics-on-Twitter)
- [OSINT and Lifecycle of Online Narratives](https://knowlesys.com/en/articles/93/OSINT_and_the_Lifecycle_of_Online_Narratives.html)
- [Event History Analysis of Online Public Opinion Duration (Frontiers)](https://www.frontiersin.org/articles/10.3389/fpsyg.2022.954559)
- [C-STEER: Lifecycle Emotional Evolution Framework](https://www.mdpi.com/2227-9709/13/1/4)
